{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продолжим работу с данными, которые были использованы в ДЗ2 и 3, продолжим решать задачу обнаружения мошеннических транзакций, что позволит получить полное решение задачи / полный пайплайн.\n",
    "\n",
    "Задание 0: выбрать любую модель машнного обучения и зафиксировать любой тип валидации. Обучить базовую модель и зафиксировать базовое качество модели. В каждом следующем задании нужно будет обучить выбранную модель и оценивать ее качество на зафиксированной схеме валидации. После каждого задания, требуется сделать вывод о достигаемом качестве модели, по сравнению с качестом из предыдущего шага.\n",
    "\n",
    "Задание 1: признак TransactionDT - это смещение в секундах относительно базовой даты. Базовая дата - 2017-12-01, преобразовать признак TransactionDT в datetime, прибавив к базовой дате исходное значение признака. Из полученного признака выделить год, месяц, день недели, час, день.\n",
    "\n",
    "Задание 2: сделать конкатенацию признаков\n",
    "* card1 + card2;\n",
    "* card1 + card2 + card_3 + card_5;\n",
    "* card1 + card2 + card_3 + card_5 + addr1 + addr2\n",
    "\n",
    "Рассматривать их как категориальных признаки.\n",
    "\n",
    "Задание 3: Сделать FrequencyEncoder для признаков card1 - card6, addr1, addr2.\n",
    "\n",
    "Задание 4: Создать признаки на основе отношения: TransactionAmt к вычисленной статистике. Статистика - среднее значение / стандартное отклонение TransactionAmt, сгруппированное по card1 - card6, addr1, addr2, и по признакам, созданным в задании 2.\n",
    "\n",
    "Задание 5: Создать признаки на основе отношения: D15 к вычисленной статистике. Статистика - среднее значение / стандартное отклонение D15, сгруппированное по card1 - card6, addr1, addr2, и по признакам, созданным в задании 2.\n",
    "\n",
    "Задание 6: выделить дробную часть и целую часть признака TransactionAmt в два отдельных признака. После создать отдельных признак - логарифм от TransactionAmt\n",
    "\n",
    "Задание 7 (опция): выполнить предварительную подготовку / очистку признаков P_emaildomain и R_emaildomain (что и как делать - остается на ваше усмотрение) и сделать Frequency Encoding для очищенных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_rel, probplot\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import catboost as cb\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_val_score, ShuffleSplit, learning_curve\n",
    "import missingno as msno\n",
    "warnings.simplefilter(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "import gc # сборщик мусора\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bootstrap_samples(data: np.array, n_samples: int = 1000) -> np.array:\n",
    "    \"\"\"\n",
    "    Создание бутстреп-выборок.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: np.array\n",
    "        Исходная выборка, которая будет использоваться для\n",
    "        создания бутстреп выборок.\n",
    "\n",
    "    n_samples: int, optional, default = 1000\n",
    "        Количество создаваемых бутстреп выборок.\n",
    "        Опциональный параметр, по умолчанию, равен 1000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bootstrap_idx: np.array\n",
    "        Матрица индексов, для создания бутстреп выборок.\n",
    "\n",
    "    \"\"\"\n",
    "    bootstrap_idx = np.random.randint(\n",
    "        low=0, high=len(data), size=(n_samples, len(data))\n",
    "    )\n",
    "    return bootstrap_idx\n",
    "\n",
    "\n",
    "def create_bootstrap_metrics(y_true: np.array,\n",
    "                             y_pred: np.array,\n",
    "                             metric: callable,\n",
    "                             n_samlpes: int = 1000) -> List[float]:\n",
    "    \"\"\"\n",
    "    Вычисление бутстреп оценок.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: np.array\n",
    "        Вектор целевой переменной.\n",
    "\n",
    "    y_pred: np.array\n",
    "        Вектор прогнозов.\n",
    "\n",
    "    metric: callable\n",
    "        Функция для вычисления метрики.\n",
    "        Функция должна принимать 2 аргумента: y_true, y_pred.\n",
    "\n",
    "    n_samples: int, optional, default = 1000\n",
    "        Количество создаваемых бутстреп выборок.\n",
    "        Опциональный параметр, по умолчанию, равен 1000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bootstrap_metrics: List[float]\n",
    "        Список со значениями метрики качества на каждой бустреп выборке.\n",
    "\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    if isinstance(y_true, pd.Series):\n",
    "        y_true = y_true.values\n",
    "\n",
    "    bootstrap_idx = create_bootstrap_samples(y_true)\n",
    "    for idx in bootstrap_idx:\n",
    "        y_true_bootstrap = y_true[idx]\n",
    "        y_pred_bootstrap = y_pred[idx]\n",
    "\n",
    "        score = metric(y_true_bootstrap, y_pred_bootstrap)\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def calculate_confidence_interval(scores: list, conf_interval: float = 0.95) -> Tuple[float]:\n",
    "    \"\"\"\n",
    "    Вычисление доверительного интервала.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scores: List[float / int]\n",
    "        Список с оценками изучаемой величины.\n",
    "\n",
    "    conf_interval: float, optional, default = 0.95\n",
    "        Уровень доверия для построения интервала.\n",
    "        Опциональный параметр, по умолчанию, равен 0.95.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    conf_interval: Tuple[float]\n",
    "        Кортеж с границами доверительного интервала.\n",
    "\n",
    "    \"\"\"\n",
    "    left_bound = np.percentile(\n",
    "        scores, ((1 - conf_interval) / 2) * 100\n",
    "    )\n",
    "    right_bound = np.percentile(\n",
    "        scores, (conf_interval + ((1 - conf_interval) / 2)) * 100\n",
    "    )\n",
    "\n",
    "    return left_bound, right_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape = 180000 rows, 394 cols\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "\n",
       "   card2  card3       card4  card5  ... V330  V331  V332  V333  V334 V335  \\\n",
       "0    NaN  150.0    discover  142.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "1  404.0  150.0  mastercard  102.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "\n",
       "  V336  V337  V338  V339  \n",
       "0  NaN   NaN   NaN   NaN  \n",
       "1  NaN   NaN   NaN   NaN  \n",
       "\n",
       "[2 rows x 394 columns]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = 'C:/Users/Kokorozaci/Downloads/assignment2_data/'\n",
    "train = pd.read_csv(PATH + \"assignment_2_train.csv\")\n",
    "test = pd.read_csv(PATH + \"assignment_2_test.csv\")\n",
    "print(\"data.shape = {} rows, {} cols\".format(*train.shape))\n",
    "train.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape = 180000 rows, 394 cols data.shape = 100001 rows, 394 cols\n"
     ]
    }
   ],
   "source": [
    "y_train = train[\"isFraud\"]\n",
    "y_test = test[\"isFraud\"]\n",
    "x_train = train.set_index('TransactionID')\n",
    "x_train = train.drop(\"isFraud\", axis=1)\n",
    "x_test = test.set_index('TransactionID')\n",
    "x_test = test.drop(\"isFraud\", axis=1)\n",
    "print(\"data.shape = {} rows, {} cols\".format(*train.shape), \"data.shape = {} rows, {} cols\".format(*test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureImputer:\n",
    "    \"\"\"Обработка категориальных фич\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.numerical_features_col=None\n",
    "        self.categorical_features_col=None\n",
    "        self.bin_features_col = None\n",
    "        self.m = None\n",
    "        self.m_P_emaildomain = None\n",
    "        self.m_ProductCD = None\n",
    "        self.m_card4 = None\n",
    "        self.m_card6 = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        self.numerical_features_col = X.select_dtypes(include=[np.number]).columns\n",
    "        self.categorical_features_col = train.select_dtypes('object').columns\n",
    "        self.m = {f: {} for f in self.categorical_features_col}\n",
    "        self.bin_features_col = []\n",
    "        for feature in self.categorical_features_col:\n",
    "            if len(X[feature].value_counts()) == 2:\n",
    "                self.bin_features_col.append(feature)\n",
    "                continue\n",
    "            self.m[feature] = {v:k for k, v in enumerate(X.groupby(feature).count().index)}\n",
    "        self.m['bin'] = {'F': 0, 'T': 1}\n",
    "    \n",
    "    def transform(self, X): \n",
    "        for feature in self.categorical_features_col:\n",
    "            if len(X[feature].value_counts()) != 2:\n",
    "                X[feature] = X[feature].map(self.m[feature])  \n",
    "        X[self.bin_features_col] = X[self.bin_features_col].apply(lambda x: x.map(self.m['bin']))\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = FeatureImputer()\n",
    "\n",
    "imputer.fit(x_train)\n",
    "\n",
    "x_test = imputer.transform(x_test)\n",
    "x_train = imputer.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bootstrap_samples(data: np.array, n_samples: int = 1000) -> np.array:\n",
    "    \"\"\"\n",
    "    Создание бутстреп-выборок.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: np.array\n",
    "        Исходная выборка, которая будет использоваться для\n",
    "        создания бутстреп выборок.\n",
    "\n",
    "    n_samples: int, optional, default = 1000\n",
    "        Количество создаваемых бутстреп выборок.\n",
    "        Опциональный параметр, по умолчанию, равен 1000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bootstrap_idx: np.array\n",
    "        Матрица индексов, для создания бутстреп выборок.\n",
    "\n",
    "    \"\"\"\n",
    "    bootstrap_idx = np.random.randint(\n",
    "        low=0, high=len(data), size=(n_samples, len(data))\n",
    "    )\n",
    "    return bootstrap_idx\n",
    "\n",
    "\n",
    "def create_bootstrap_metrics(y_true: np.array,\n",
    "                             y_pred: np.array,\n",
    "                             metric: callable,\n",
    "                             n_samlpes: int = 1000) -> List[float]:\n",
    "    \"\"\"\n",
    "    Вычисление бутстреп оценок.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: np.array\n",
    "        Вектор целевой переменной.\n",
    "\n",
    "    y_pred: np.array\n",
    "        Вектор прогнозов.\n",
    "\n",
    "    metric: callable\n",
    "        Функция для вычисления метрики.\n",
    "        Функция должна принимать 2 аргумента: y_true, y_pred.\n",
    "\n",
    "    n_samples: int, optional, default = 1000\n",
    "        Количество создаваемых бутстреп выборок.\n",
    "        Опциональный параметр, по умолчанию, равен 1000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bootstrap_metrics: List[float]\n",
    "        Список со значениями метрики качества на каждой бустреп выборке.\n",
    "\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    if isinstance(y_true, pd.Series):\n",
    "        y_true = y_true.values\n",
    "\n",
    "    bootstrap_idx = create_bootstrap_samples(y_true)\n",
    "    for idx in bootstrap_idx:\n",
    "        y_true_bootstrap = y_true[idx]\n",
    "        y_pred_bootstrap = y_pred[idx]\n",
    "\n",
    "        score = metric(y_true_bootstrap, y_pred_bootstrap)\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def calculate_confidence_interval(scores: list, conf_interval: float = 0.95) -> Tuple[float]:\n",
    "    \"\"\"\n",
    "    Вычисление доверительного интервала.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scores: List[float / int]\n",
    "        Список с оценками изучаемой величины.\n",
    "\n",
    "    conf_interval: float, optional, default = 0.95\n",
    "        Уровень доверия для построения интервала.\n",
    "        Опциональный параметр, по умолчанию, равен 0.95.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    conf_interval: Tuple[float]\n",
    "        Кортеж с границами доверительного интервала.\n",
    "\n",
    "    \"\"\"\n",
    "    left_bound = np.percentile(\n",
    "        scores, ((1 - conf_interval) / 2) * 100\n",
    "    )\n",
    "    right_bound = np.percentile(\n",
    "        scores, (conf_interval + ((1 - conf_interval) / 2)) * 100\n",
    "    )\n",
    "\n",
    "    return left_bound, right_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adversarial_validation:\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.y_pred = None\n",
    "    \n",
    "    def fit(self, X_train, X_test):\n",
    "        x_adv = pd.concat([x_train, x_test], axis=0)\n",
    "        y_adv = np.hstack((np.zeros(x_train.shape[0]), np.ones(x_test.shape[0])))\n",
    "        assert x_adv.shape[0] == y_adv.shape[0]\n",
    "        \n",
    "        x_adv = x_adv.drop(['TransactionID', 'TransactionDT'], axis=1)\n",
    "        \n",
    "        self.model.fit(x_adv, y_adv)\n",
    "        \n",
    "        y_pred_adv = self.model.predict_proba(x_adv)\n",
    "        score = roc_auc_score(y_adv, y_pred_adv[:, 1])\n",
    "        print(round(score, 4))\n",
    "        \n",
    "        x_t = X_train.copy().drop(['TransactionID', 'TransactionDT'], axis=1)\n",
    "        self.y_pred = self.model.predict_proba(x_t)\n",
    "        \n",
    "    def split(self, X, y):\n",
    "        \n",
    "        X_valid, y_valid = X[self.y_pred[:, 1] >= 0.5], y[self.y_pred[:, 1] >= 0.5]\n",
    "        X_train, y_train = X[self.y_pred[:, 1] < 0.5], y[self.y_pred[:, 1] < 0.5]\n",
    "        x_valid.shape\n",
    "        \n",
    "        return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8863\n"
     ]
    }
   ],
   "source": [
    "av = Adversarial_validation(xgb.XGBClassifier(n_estimators=10))\n",
    "av.fit(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_features(x_train, y_train):\n",
    "\n",
    "    x_train_base, y_train_base, x_valid, y_valid = av.split(x_train, y_train)\n",
    "\n",
    "    dtrain = xgb.DMatrix(\n",
    "            data=x_train_base, label=y_train_base\n",
    "        )\n",
    "    dvalid = xgb.DMatrix(\n",
    "            data=x_valid, label=y_valid\n",
    "        )\n",
    "\n",
    "    dtrain_all = xgb.DMatrix(\n",
    "            data=x_train, label=y_train\n",
    "        )\n",
    "    \n",
    "    params = {\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"n_estimators\": 1000,\n",
    "        \"reg_lambda\": 100,\n",
    "        \"max_depth\": 4,\n",
    "        \"gamma\": 10,\n",
    "        \"nthread\": 6,\n",
    "        \"seed\": 27\n",
    "        }\n",
    "\n",
    "    final_model = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=10000,\n",
    "            early_stopping_rounds=50,\n",
    "            evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n",
    "            verbose_eval=None,\n",
    "            maximize=True,\n",
    "        )\n",
    "\n",
    "\n",
    "    cv_result_cat = xgb.cv(\n",
    "        params=params,\n",
    "        dtrain=dtrain_all,\n",
    "        num_boost_round=10000,\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=None,\n",
    "        stratified=True,\n",
    "        metrics=\"auc\",\n",
    "        maximize=True,\n",
    "        shuffle=True,\n",
    "        nfold=3,\n",
    "    )\n",
    "    \n",
    "    train_score = roc_auc_score(y_train_base, final_model.predict(dtrain))\n",
    "    test_score = roc_auc_score(y_valid, final_model.predict(dvalid))\n",
    "\n",
    "    scores = create_bootstrap_metrics(y_valid, final_model.predict(dvalid), roc_auc_score)\n",
    "\n",
    "    print(f\"Train-score: {round(train_score, 3)}, Test-score: {round(test_score, 3)}\")\n",
    "    print(f\"CV-results: {cv_result_cat.loc[cv_result_cat.index[-1], ['test-auc-mean', 'test-auc-std'] ]}\")\n",
    "    print(calculate_confidence_interval(scores))\n",
    "    \n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:55:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:57:18] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:57:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:57:20] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Train-score: 0.92, Test-score: 0.86\n",
      "CV-results: test-auc-mean    0.903114\n",
      "test-auc-std     0.001776\n",
      "Name: 173, dtype: float64\n",
      "(0.8142575724063467, 0.8999876611157724)\n"
     ]
    }
   ],
   "source": [
    "final_model = test_features(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 1: признак TransactionDT - это смещение в секундах относительно базовой даты. Базовая дата - 2017-12-01, преобразовать признак TransactionDT в datetime, прибавив к базовой дате исходное значение признака. Из полученного признака выделить год, месяц, день недели, час, день."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>...</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day of week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>4</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 398 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  TransactionDT  TransactionAmt  ProductCD  card1  card2  \\\n",
       "0        2987000          86400            68.5          4  13926    NaN   \n",
       "1        2987001          86401            29.0          4   2755  404.0   \n",
       "\n",
       "   card3  card4  card5  card6  ...  V335  V336  V337  V338  V339  Year  Month  \\\n",
       "0  150.0    1.0  142.0    1.0  ...   NaN   NaN   NaN   NaN   NaN  2017     12   \n",
       "1  150.0    2.0  102.0    1.0  ...   NaN   NaN   NaN   NaN   NaN  2017     12   \n",
       "\n",
       "   Day of week  Day  Hour  \n",
       "0            5    2     0  \n",
       "1            5    2     0  \n",
       "\n",
       "[2 rows x 398 columns]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_name = 'TransactionDT'\n",
    "base = '2017-12-01'\n",
    "def datetime_transform(df, feature_name, base):\n",
    "    X = df.copy()\n",
    "    X[f'{feature_name}_time'] = base\n",
    "    X[f'{feature_name}_time'] = pd.to_datetime(X[f'{feature_name}_time']) + pd.to_timedelta(X[feature_name], unit='s')\n",
    "    X.set_index(f'{feature_name}_time', inplace=True)\n",
    "    X['Year'] = X.index.year\n",
    "    X['Month'] = X.index.month\n",
    "    X['Day of week'] = X.index.dayofweek\n",
    "    X['Day'] = X.index.day\n",
    "    X['Hour'] = X.index.hour\n",
    "    X.reset_index(inplace=True)\n",
    "    X.drop(f'{feature_name}_time', axis=1, inplace=True)\n",
    "    return X\n",
    "x_train = datetime_transform(x_train, base_name, base)\n",
    "x_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:15:28] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:17:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:17:31] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:17:32] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Train-score: 0.92, Test-score: 0.859\n",
      "CV-results: test-auc-mean    0.903629\n",
      "test-auc-std     0.001906\n",
      "Name: 144, dtype: float64\n",
      "(0.8140769337182461, 0.899805274012838)\n"
     ]
    }
   ],
   "source": [
    "final_model = test_features(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 2: сделать конкатенацию признаков\n",
    "\n",
    "card1 + card2;\n",
    "\n",
    "card1 + card2 + card_3 + card_5;\n",
    "\n",
    "card1 + card2 + card_3 + card_5 + addr1 + addr2\n",
    "\n",
    "Рассматривать их как категориальных признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def new_category(df):\n",
    "    X = df.copy()\n",
    "    X['card1 + card2'] = X['card1'].astype('str') + ' | ' + X['card2'].astype('str') \n",
    "    X['card1 + card2 + card3 + card5'] = X['card1'].astype('str')  + ' | ' + X['card2'].astype('str')+ ' | '  + X['card3'].astype('str')  + ' | ' + X['card5'].astype('str') \n",
    "    X['card1 + card2 + card3 + card5 + addr1 + addr2'] = X['card1'].astype('str')  + ' | ' + X['card2'].astype('str')  + ' | '+ X['card3'].astype('str')  + ' | ' + X['card5'].astype('str')  + ' | ' + X['addr1'].astype('str')  + ' | ' + X['addr2'].astype('str') \n",
    "    return X\n",
    "x_train = new_category(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['card1 + card2',\n",
    "            'card1 + card2 + card3 + card5',\n",
    "            'card1 + card2 + card3 + card5 + addr1 + addr2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = FrequencyEncoder(features)\n",
    "\n",
    "encoder.fit(x_train)\n",
    "\n",
    "x_train = encoder.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:35:32] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:37:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:37:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:37:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Train-score: 0.918, Test-score: 0.859\n",
      "CV-results: test-auc-mean    0.899795\n",
      "test-auc-std     0.002553\n",
      "Name: 138, dtype: float64\n",
      "(0.8148672327407076, 0.8989859650155663)\n"
     ]
    }
   ],
   "source": [
    "final_model = test_features(x_train.drop(cat_features, axis=1), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 3: Сделать FrequencyEncoder для признаков card1 - card6, addr1, addr2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrequencyEncoder:\n",
    "    \"\"\"FrequencyEncoder\"\"\"\n",
    "    \n",
    "    def __init__(self, categorical_features):\n",
    "        self.categorical_features= categorical_features\n",
    "        self.m = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        self.m = {f: {} for f in self.categorical_features}\n",
    "        for feature in self.categorical_features:\n",
    "            self.m[feature] = X[feature].value_counts(normalize=True).to_dict()\n",
    "    \n",
    "    def transform(self, X): \n",
    "        for feature in self.categorical_features:\n",
    "            X[f'{feature}_freq_encoding'] = X[feature].map(self.m[feature])\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['card1', 'card2', 'card3', 'card4',\n",
    "            'card5', 'card6', 'addr1', 'addr2']\n",
    "encoder = FrequencyEncoder(features)\n",
    "\n",
    "encoder.fit(x_train)\n",
    "\n",
    "x_train = encoder.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:54:24] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:56:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:56:45] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:56:46] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Train-score: 0.922, Test-score: 0.866\n",
      "CV-results: test-auc-mean    0.905859\n",
      "test-auc-std     0.001455\n",
      "Name: 150, dtype: float64\n",
      "(0.8210098183584115, 0.9036691552955908)\n"
     ]
    }
   ],
   "source": [
    "final_model = test_features(x_train.drop(cat_features, axis=1), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 4: Создать признаки на основе отношения: \n",
    "\n",
    "TransactionAmt к вычисленной статистике. \n",
    "\n",
    "Статистика - среднее значение / стандартное отклонение TransactionAmt, \n",
    "\n",
    "сгруппированное по card1 - card6, addr1, addr2, и по признакам, созданным в задании 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "group_list = ['card1', 'card2', 'card3', 'card4',\n",
    "              'card5', 'card6', 'addr1', 'addr2',\n",
    "              'card1 + card2', 'card1 + card2 + card3 + card5', \n",
    "              'card1 + card2 + card3 + card5 + addr1 + addr2']\n",
    "stat_list = ['mean', 'std']\n",
    "def feature_ratio(X, features, group_list, stat_list):\n",
    "    agg_dict = {feature: stat_list for feature in features}\n",
    "    group_dict = {}\n",
    "    for group in group_list:\n",
    "        df = X.groupby(group, as_index=False).agg(agg_dict)\n",
    "        df.columns = [f'{group}_{\"_\".join(x)}' for x in df.columns.ravel()]\n",
    "        df = df.rename(columns={df.columns[0]:group})\n",
    "        X = X.merge(df, on=[group], how='left')\n",
    "    for feature in features:\n",
    "        columns = [col for col in X.columns if feature in col]\n",
    "        X[columns[1:]] = np.repeat([X[columns[0]].values], repeats=len(columns)-1, axis=0).T/ X[columns[1:]].values\n",
    "    return X\n",
    "\n",
    "features = ['TransactionAmt']\n",
    "\n",
    "x_train = feature_ratio(x_train, features, group_list, stat_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:03:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:06:42] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:06:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:06:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Train-score: 0.924, Test-score: 0.86\n",
      "CV-results: test-auc-mean    0.907595\n",
      "test-auc-std     0.002286\n",
      "Name: 160, dtype: float64\n",
      "(0.8155875085185057, 0.8994701391908796)\n"
     ]
    }
   ],
   "source": [
    "final_model = test_features(x_train.drop(cat_features, axis=1), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 5: Создать признаки на основе отношения: D15 к вычисленной статистике. Статистика - среднее значение / стандартное отклонение D15, сгруппированное по card1 - card6, addr1, addr2, и по признакам, созданным в задании 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['D15']\n",
    "\n",
    "x_train = feature_ratio(x_train, features, group_list, stat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:13:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:17:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:17:04] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:17:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Train-score: 0.924, Test-score: 0.862\n",
      "CV-results: test-auc-mean    0.907318\n",
      "test-auc-std     0.002042\n",
      "Name: 171, dtype: float64\n",
      "(0.8183582731803614, 0.9015484872240581)\n"
     ]
    }
   ],
   "source": [
    "final_model = test_features(x_train.drop(cat_features, axis=1), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 6: выделить дробную часть и целую часть признака TransactionAmt в два отдельных признака. После создать отдельных признак - логарифм от TransactionAmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionAmt_int</th>\n",
       "      <th>TransactionAmt_frac</th>\n",
       "      <th>TransactionAmt_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.226834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.367296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionAmt_int  TransactionAmt_frac  TransactionAmt_log\n",
       "0                68.0                  0.5            4.226834\n",
       "1                29.0                  0.0            3.367296"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['TransactionAmt_int'] = x_train['TransactionAmt']//1\n",
    "x_train['TransactionAmt_frac'] = x_train['TransactionAmt']%1\n",
    "x_train['TransactionAmt_log'] = np.log(x_train['TransactionAmt'])\n",
    "x_train[['TransactionAmt_int', 'TransactionAmt_frac', 'TransactionAmt_log']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:24:26] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:27:41] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:27:42] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:27:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Train-score: 0.926, Test-score: 0.862\n",
      "CV-results: test-auc-mean    0.906850\n",
      "test-auc-std     0.001802\n",
      "Name: 161, dtype: float64\n",
      "(0.8179520422450302, 0.900944992084082)\n"
     ]
    }
   ],
   "source": [
    "final_model = test_features(x_train.drop(cat_features, axis=1), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 7 (опция): выполнить предварительную подготовку / очистку признаков P_emaildomain и R_emaildomain (что и как делать - остается на ваше усмотрение) и сделать Frequency Encoding для очищенных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emaildomain(X):\n",
    "    X['P_emaildomain_name'] = X['P_emaildomain'].astype('str').str.split('.').apply(lambda s:s[0])\n",
    "    X['P_emaildomain_domain'] = X['P_emaildomain'].astype('str').str.split('.').apply(lambda s:'.'.join(s[1:]))\n",
    "    X['R_emaildomain_name'] = X['R_emaildomain'].astype('str').str.split('.').apply(lambda s:s[0])\n",
    "    X['R_emaildomain_domain'] = X['R_emaildomain'].astype('str').str.split('.').apply(lambda s:'.'.join(s[1:]))\n",
    "    X.loc[X['R_emaildomain_name'] == 'nan', 'R_emaildomain_name'] = np.NaN\n",
    "    X.loc[X['R_emaildomain_domain'] == '', 'R_emaildomain_domain'] = np.NaN\n",
    "    X.loc[X['P_emaildomain_name'] == 'nan', 'P_emaildomain_name'] = np.NaN\n",
    "    X.loc[X['P_emaildomain_domain'] == '', 'P_emaildomain_domain'] = np.NaN\n",
    "    X['P_R_domain'] = X['R_emaildomain_domain'] + ' | ' + X['P_emaildomain_domain']\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = emaildomain(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['P_emaildomain_name', 'P_emaildomain_domain', 'P_R_domain',\n",
    "            'R_emaildomain_name', 'R_emaildomain_domain']\n",
    "encoder = FrequencyEncoder(features)\n",
    "\n",
    "encoder.fit(x_train)\n",
    "\n",
    "x_train = encoder.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features.extend(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:38:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:41:42] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:41:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:41:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Train-score: 0.924, Test-score: 0.858\n",
      "CV-results: test-auc-mean    0.907309\n",
      "test-auc-std     0.002236\n",
      "Name: 155, dtype: float64\n",
      "(0.8140861747438145, 0.8976924670714873)\n"
     ]
    }
   ],
   "source": [
    "final_model = test_features(x_train.drop(cat_features, axis=1), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы ###\n",
    "\n",
    "0 __Базовое состояние датасета (с прошлого домашнего задания) __\n",
    "\n",
    "Train-score: 0.92, Test-score: __0.86__\n",
    "\n",
    "CV-results: test-auc-mean    __0.903114__\n",
    "            test-auc-std     0.001776\n",
    "\n",
    "(0.8142575724063467, 0.8999876611157724)\n",
    "\n",
    "1 __Score после преобразования заты и выделения из неё дней, часов и т.д.__\n",
    "\n",
    "Ничего не изменилось, возможно данные признаки сами по себе не несут много информации. Их можно попробовать использовать для признаков основанных на группировках.\n",
    "\n",
    "Train-score: 0.92, Test-score: 0.859\n",
    "\n",
    "CV-results: test-auc-mean    0.903629\n",
    "            test-auc-std     0.001906\n",
    "\n",
    "(0.8140769337182461, 0.899805274012838)\n",
    "\n",
    "2 __Score после создания признаков на основе канкотинации категориальных признаков (эти признаки закодированы частотным кодированием) __\n",
    "\n",
    "Скор стал хуже\n",
    "\n",
    "Train-score: 0.918, Test-score: 0.859\n",
    "\n",
    "CV-results: test-auc-mean    0.899795\n",
    "            test-auc-std     0.002553\n",
    "\n",
    "(0.8148672327407076, 0.8989859650155663)\n",
    "\n",
    "3 __Score после частотного кодирования признаков card.. и addr.. __\n",
    "\n",
    "По сравнениию с базовой моделью score вырос на 0,5%, качество на кроссвалидации выросло на 0,2%\n",
    "\n",
    "Train-score: 0.922, Test-score: 0.866\n",
    "\n",
    "CV-results: test-auc-mean    0.905859\n",
    "            test-auc-std     0.001455\n",
    "\n",
    "(0.8210098183584115, 0.9036691552955908)\n",
    "\n",
    "4 __Score после создания признаков на основе отношения: TransactionAmt к вычисленной статистике__\n",
    "\n",
    "По сравнениию с п.3 качество на кроссвалидации выросло ещё на 0,2%, но качество на отложенной выборке опять упало и доверительный интервал сместиля в меньшую сторону\n",
    "\n",
    "Train-score: 0.924, Test-score: 0.86\n",
    "\n",
    "CV-results: test-auc-mean    0.907595\n",
    "            test-auc-std     0.002286\n",
    "\n",
    "(0.8155875085185057, 0.8994701391908796)\n",
    "\n",
    "5 __Score после создания признаков на основе отношения: D15 к вычисленной статистике__\n",
    "\n",
    "По сравнениию с п.4 качество на кроссвалидации почти не изменилось, а качество на отложенной выборке увеличелось, так же как и границы доверительного интервала, хотя в п.3 качество всё ещё лучше\n",
    "\n",
    "Train-score: 0.924, Test-score: 0.862\n",
    "\n",
    "CV-results: test-auc-mean    0.907318\n",
    "            test-auc-std     0.002042\n",
    "\n",
    "(0.8183582731803614, 0.9015484872240581)\n",
    "\n",
    "6 __Score после преобразований TransactionAmt__\n",
    "\n",
    "Стало незначительно хуже, по сравнению с п 5.\n",
    "\n",
    "Train-score: 0.926, Test-score: 0.862\n",
    "\n",
    "CV-results: test-auc-mean    0.906850\n",
    "            test-auc-std     0.001802\n",
    "\n",
    "(0.8179520422450302, 0.900944992084082)\n",
    "\n",
    "7 __Score после обработки emaildomain__\n",
    "\n",
    "Проверила гипотизу о том что страна емейла и сайт емейла имеют значение. Частотная кодировка качество только ухудшила. Но эти признаки можно закодировать иначе, например сруппировать по ним статистики или вычеслить среднее по таргету для каждого из признаков (естественно убрав те, которые встречаются меньше 15 раз или около того, чтобы избежать переобучения)\n",
    "\n",
    "Train-score: 0.924, Test-score: 0.858\n",
    "\n",
    "CV-results: test-auc-mean    0.907309\n",
    "            test-auc-std     0.002236\n",
    "\n",
    "(0.8140861747438145, 0.8976924670714873)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
